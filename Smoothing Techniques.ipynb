{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfdf5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7033f441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\y22cm84\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f6995bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count: \n",
      "Counter({'the': 4, 'cat': 1, 'sat': 1, 'on': 1, 'mat': 1, 'quick': 1, 'brown': 1, 'fox': 1, 'jumps': 1, 'over': 1, 'lazy': 1, 'dog': 1})\n",
      "Total count: 15\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    'the', 'cat', 'sat', 'on', 'the', 'mat',\n",
    "    'the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'\n",
    "]\n",
    "\n",
    "v = Counter(corpus)\n",
    "n = sum(v.values())\n",
    "\n",
    "print(f\"Word count: \\n{v}\")\n",
    "print(f\"Total count: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8c85143",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = len(v)\n",
    "total_vocab = vocab+n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c422816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilities:\n",
      "the, 0.3333\n",
      "cat, 0.1333\n",
      "sat, 0.1333\n",
      "on, 0.1333\n",
      "mat, 0.1333\n",
      "quick, 0.1333\n",
      "brown, 0.1333\n",
      "fox, 0.1333\n",
      "jumps, 0.1333\n",
      "over, 0.1333\n",
      "lazy, 0.1333\n",
      "dog, 0.1333\n"
     ]
    }
   ],
   "source": [
    "# laplace smoothing\n",
    "\n",
    "probs = {}\n",
    "for word, count in v.items():\n",
    "    probs[word] = (count + 1) / n\n",
    "\n",
    "print(\"\\nProbabilities:\")\n",
    "for key, value in probs.items():\n",
    "    print(f\"{key}, {round(value, 4)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51e8426b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilities: \n",
      "the, 0.2143\n",
      "cat, 0.0714\n",
      "sat, 0.0714\n",
      "on, 0.0714\n",
      "mat, 0.0714\n",
      "quick, 0.0714\n",
      "brown, 0.0714\n",
      "fox, 0.0714\n",
      "jumps, 0.0714\n",
      "over, 0.0714\n",
      "lazy, 0.0714\n",
      "dog, 0.0714\n"
     ]
    }
   ],
   "source": [
    "# Add-k Smoothing\n",
    "\n",
    "k=0.5\n",
    "additive_probs = {}\n",
    "for word, count in v.items():\n",
    "    var = (count + k) / (n + k * vocab)\n",
    "    additive_probs[word] = var\n",
    "\n",
    "print(\"\\nProbabilities: \")\n",
    "for key, value in additive_probs.items():\n",
    "    print(f\"{key}, {round(value, 4)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ed6f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the data\n",
    "tokenized_corpus = []\n",
    "for sentence in corpus:\n",
    "    var = sentence.lower()\n",
    "    var = word_tokenize(sentence)\n",
    "    tokenized_corpus.append(var)\n",
    "\n",
    "corpus_words = []\n",
    "for i in tokenized_corpus:\n",
    "    for word in i:\n",
    "        corpus_words.append(word)\n",
    "    \n",
    "vocab = set(corpus_words)\n",
    "def grams(n):\n",
    "    result = []\n",
    "    for i in range(len(corpus_words)-n+1):\n",
    "        result.append(tuple(corpus_words[i:i+n]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5927252",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = grams(1)\n",
    "unigram_counter = Counter(unigram)\n",
    "bigrams = grams(2)\n",
    "bigrams_counter = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa7c7131",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_prob = {unigram: count / n for unigram, count in unigram_counter.items()}\n",
    "bigram_prob = {bigram: count / n for bigram, count in bigrams_counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a4123e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'cat'), 0.0467\n",
      "('cat', 'sat'), 0.0467\n",
      "('sat', 'on'), 0.0467\n",
      "('on', 'the'), 0.0467\n",
      "('the', 'mat'), 0.0467\n",
      "('mat', 'the'), 0.0467\n",
      "('the', 'quick'), 0.0467\n",
      "('quick', 'brown'), 0.0467\n",
      "('brown', 'fox'), 0.0467\n",
      "('fox', 'jumps'), 0.0467\n",
      "('jumps', 'over'), 0.0467\n",
      "('over', 'the'), 0.0467\n",
      "('the', 'lazy'), 0.0467\n",
      "('lazy', 'dog'), 0.0467\n"
     ]
    }
   ],
   "source": [
    "# Interpolated smoothing\n",
    "\n",
    "l1 = 0.7\n",
    "l2 = 0.3\n",
    "\n",
    "interpolated_prob = {}\n",
    "for (w1, w2), count in bigrams_counter.items():\n",
    "    bigram_p = bigram_prob.get((w1, w2), 0)\n",
    "    unigram_p = unigram_prob.get(w2, 0)\n",
    "    \n",
    "    interpolated_prob[(w1, w2)] = l1 * bigram_p + l2 * unigram_p\n",
    "\n",
    "for key, value in interpolated_prob.items():\n",
    "    print(f\"{key}, {round(value, 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
